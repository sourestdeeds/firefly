{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# firefly\n",
    "A collection of tools to aid the user experience in the use of TransitFit for confirmed TESS targets.\n",
    "#### Installation \n",
    "```bash\n",
    "python setup.py install\n",
    "```\n",
    "\n",
    "#### Dependancies\n",
    "```\n",
    "transitfit\n",
    "tabulate\n",
    "python-Levenshtein\n",
    "fuzzywuzzy\n",
    "numpy\n",
    "pandas\n",
    "```\n",
    "#### Description\n",
    "- Targets passed are corrected for basic user input. 'wasp43b' is\n",
    "interpreted as 'WASP-43 b'. List must be of the form given in the example below.\n",
    "- Initial checks for targets from the exoplanet archive are then taken to ascertain \n",
    "whether the prior data extracted has entries in all columns. If there are missing\n",
    "entries for a given target in the list, the user will be asked whether to proceed.\n",
    "- Iteratively takes the targets given and employs TransitFit across each TESS sector \n",
    "for every exoplanet in the list given.\n",
    "- If more than one target is given in a list, multiple cpu's will handle the extra\n",
    "targets in seperate threads. The default for this behaviour is set to a\n",
    "quarter of the maximum cores available to the current process.\n",
    "- All available split curves are fitted with TransitFit, then the results\n",
    "are then zipped up and time stamped. Optionally sends an email upon an error or \n",
    "full completion of a target.\n",
    "- The printing of all but essential output such as exceptions are disabled. \n",
    "If you wish to run the fitting procedure for a list in piecemeal across a \n",
    "single core, set the processess variable to 1 and the list will be worked \n",
    "through one by one. It is advised that you only set the variable printing \n",
    "to True when fitting in this manner. Multiple cores give a chaotic output, \n",
    "and impacts performance.\n",
    "- Email is also disabled by default. If enabled, status updates on completion\n",
    "and exceptions with the full traceback are sent. (Unfinished)\n",
    "\n",
    "Background tasks for feeding data to TransitFit include:\n",
    "- Set the filter path to the TESS Filter.\n",
    "- Download EU/NASA exoplanet archive data every 10 days (checks the file age).\n",
    "- Download MAST lightcurve data for target TESS Sectors.\n",
    "- Split the lightcurves into seperate transits or epochs.\n",
    "- Create the data paths to each seperate epoch.\n",
    "- Run TransitFit.\n",
    "- Delete all downloaded data and inputs.\n",
    "- Zip up and timestamp the output.\n",
    "\n",
    "An example use with TransitFit is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from firefly import firefly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a single target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ('WASP-43 b',)\n",
    "firefly(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a list of targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ('WASP-43 b', 'WASP-18 b', 'WASP-91 b', 'WASP-12 b',\n",
    "           'WASP-126 b', 'LHS 3844 b', 'GJ 1252 b', 'TOI-270 b')\n",
    "firefly(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a list of random viable tess targets with full prior info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from firefly import tess_viable\n",
    "targets = tess_viable(k=10)\n",
    "firefly(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simply use the default fitting settings on a random viable target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firefly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full set of variables are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = tess_viable(k=10)\n",
    "firefly(\n",
    "    # Firefly Interface\n",
    "    targets, \n",
    "    archive='nasa', \n",
    "    curve_sample=0.01, \n",
    "    email=True,\n",
    "    to=['your.email@gmail.com'], \n",
    "    clean=False,\n",
    "    # TransitFit Variables\n",
    "    cutoff=0.25,\n",
    "    window=2.5,\n",
    "    nlive=300, \n",
    "    fit_ttv=False,\n",
    "    detrending_list=[['nth order', 2]],\n",
    "    dynesty_sample='rslice', \n",
    "    fitting_mode='folded',\n",
    "    limb_darkening_model='quadratic', \n",
    "    ld_fit_method='coupled',\n",
    "    max_batch_parameters=25, \n",
    "    batch_overlap=2, \n",
    "    dlogz=None, \n",
    "    maxiter=None, \n",
    "    maxcall=None, \n",
    "    dynesty_bounding='multi', \n",
    "    normalise=True, \n",
    "    detrend=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters\n",
    "----------\n",
    "    \n",
    "#### targets : str, list\n",
    "A list of exoplanet targets.\n",
    "Input is a list tuple of strings:\n",
    "```python\n",
    "('WASP-43 b', 'WASP-18 b', 'WASP-91 b')\n",
    "```    \n",
    "#### archive : str, optional\n",
    "The exoplanet archive to use for priors. Supports:\n",
    "\n",
    "- 'eu'\n",
    "- 'nasa'\n",
    "The default is `'eu'`.\n",
    "\n",
    "#### curve_sample : int {0 < curve_sample <= 1}, optional\n",
    "The fraction of curves generated to fit against. For example, setting\n",
    "```python\n",
    "curve_sample = 0.5\n",
    "```\n",
    "will fit half the curves extracted. The formula for this works as:\n",
    "```python\n",
    "total_curves = curves_extracted * curve_sample\n",
    "```\n",
    "Always returns an int. For example:\n",
    "```python\n",
    "curve_sample = 0.001\n",
    "```\n",
    "will fit using only 1 lightcurve from each sector. \n",
    "The default is `1` to fit all lightcurves across all sectors.\n",
    "\n",
    "#### email : bool, optional\n",
    "If True will send status emails. The default is `False`.\n",
    "#### to : str, optional\n",
    "The email address to send status updates to.\n",
    "```python\n",
    "to=['transitfit.server@gmail.com']\n",
    "```\n",
    "#### clean : bool, optional\n",
    "If True will delete all downloaded files and zip outputs only.\n",
    "The default is `False`.\n",
    "#### cutoff : float, optional\n",
    "If there are no data within \n",
    "```python\n",
    "t14 * cutoff of t0, \n",
    "```\n",
    "a period will be discarded. Default is `0.25`.\n",
    "#### window : float, optional\n",
    "Data outside of the range \n",
    "```python\n",
    "[t0 Â± (0.5 * t14) * window] \n",
    "```\n",
    "will be discarded.\n",
    "#### nlive : int, optional\n",
    "The number of live points to use in the nested sampling retrieval.\n",
    "Default is `1000`.\n",
    "#### detrending_list : array_like, shape (n_detrending_models, 2)\n",
    "A list of different detrending models. Each entry should consist\n",
    "of a method and a second parameter dependent on the method.\n",
    "Accepted methods are:\n",
    "\n",
    "- ['nth order', order]\n",
    "- ['custom', function, [global fit indices, filter fit indices, epoch fit indices]]\n",
    "- ['off', ]\n",
    "Function here is a custom detrending function. TransitFit assumes\n",
    "that the first argument to this function is times and that all\n",
    "other arguments are single-valued - TransitFit cannot fit\n",
    "list/array variables. If `'off'` is used, no detrending will be\n",
    "applied to the `LightCurves` using this model.\n",
    "If a custom function is used, and some inputs to the function\n",
    "should not be fitted individually for each light curve, but should\n",
    "instead be shared either globally, within a given filter, or within\n",
    "a given epoch, the indices of where these fall within the arguments\n",
    "of the detrending function should be given as a list. If there are\n",
    "no indices to be given, then use an empty list: []\n",
    "e.g. if the detrending function is given by\n",
    "```python\n",
    "foo(times, a, b, c):\n",
    "    do something\n",
    "```\n",
    "and a should be fitted globally, then the entry in the method_list\n",
    "would be \n",
    "\n",
    "- ['custom', foo, [1], [], []].\n",
    "\n",
    "#### dynesty_sample : str, optional\n",
    "Method used to sample uniformly within the likelihood constraint,\n",
    "conditioned on the provided bounds. Unique methods available are:\n",
    "\n",
    "- uniform sampling within the bounds(`'unif'`) \n",
    "- random walks with fixed proposals (`'rwalk'`) \n",
    "- random walks with variable (\"staggering\") proposals (`'rstagger'`) \n",
    "- multivariate slice sampling along preferred orientations (`'slice'`) \n",
    "- \"random\" slice sampling along all orientations (`'rslice'`) \n",
    "- \"Hamiltonian\" slices along random trajectories (`'hslice'`) \n",
    "and any callable function which follows\n",
    "the pattern of the sample methods defined in dynesty.sampling.\n",
    "'auto' selects the sampling method based on the dimensionality of\n",
    "the problem (from ndim). \n",
    "- When ndim < 10, this defaults to `'unif'`.\n",
    "- When 10 <= ndim <= 20, this defaults to `'rwalk'`. \n",
    "- When ndim > 20, this defaults to `'hslice'` if a gradient is provided \n",
    "  and `'slice'` otherwise. \n",
    "- `'rstagger'` and `'rslice'` are provided as alternatives for\n",
    "  `'rwalk'` and `'slice'`, respectively. Default is `'auto'`.\n",
    "#### fitting_mode : {`'auto'`, `'all'`, `'folded'`, `'batched'`}, optional\n",
    "The approach TransitFit takes towards limiting the number of parameters\n",
    "being simultaneously fitted. The available modes are:\n",
    "\n",
    "- `'auto'` : Will calculate the number of parameters required to fit\n",
    "  all the data simulataneously. If this is less than max_parameters,\n",
    "  will set to `'all'` mode, else will set to `'folded'` if at least one\n",
    "  filter has at least 3 epochs in it. Otherwise will set to `'batched'`\n",
    "- `'all'` : Fits all parameters simultaneously, with no folding or\n",
    "  batching of curves. Should be used with caution when fitting very\n",
    "  large (~< 30) numbers of parameters.\n",
    "- `'folded'` : Useful for fitting curves with multiple epochs for each\n",
    "  filter. TransitFit will fit each filter separately and produce a\n",
    "  period-folded light curve for each filter, before fitting these\n",
    "  simultaneously, using the `'batched'` approach if required.\n",
    "- `'batched'` : Useful for large numbers of light curves with\n",
    "  relatively few shared filters, so `'folded'` loses large amounts of\n",
    "  multi-epoch information. This mode splits the filters into sets of\n",
    "  overlapping batches, runs each batch and uses the weighted means of\n",
    "  each batch to produce a final result.\n",
    "Default is `'auto'`.\n",
    "#### fit_ttv : boolean, optional\n",
    "DESCRIPTION. The default is `False`.\n",
    "#### limb_darkening_model : str, optional\n",
    "The limb darkening model to use. Allowed models are\n",
    "\n",
    "- `'linear'`\n",
    "- `'quadratic'`\n",
    "- `'squareroot'`\n",
    "- `'power2'`\n",
    "- `'nonlinear'`\n",
    "With the exception of the non-linear model, all models are constrained\n",
    "by the method in Kipping (2013), which can be found at\n",
    "https://arxiv.org/abs/1308.0009. Use `ldc_low_lim` and `ldc_high_lim`\n",
    "to control the behaviour of unconstrained coefficients.\n",
    "Default is `'quadratic'`.\n",
    "#### ld_fit_method : {`'coupled'`, `'single'`, `'independent'`, `'off'`}, optional\n",
    "Determines the mode of fitting of limb darkening parameters. The\n",
    "available modes are:\n",
    "\n",
    "- `'coupled'` : all limb darkening parameters are fitted\n",
    "  independently, but are coupled to a wavelength dependent\n",
    "  model based on the host parameters through `ldkt`\n",
    "- `'single'` : LD parameters are still tied to a model, but\n",
    "  only the first filter is actively fitted. The remaining\n",
    "  filters are estimated based off the ratios given by ldtk for\n",
    "  a host with the given parameters. This mode is useful for a\n",
    "  large number of filters, as `'coupled'` or `'independent'`\n",
    "  fitting will lead to much higher computation times.\n",
    "- `'independent'` : Each LD coefficient is fitted separately for\n",
    "  each filter, with no coupling to the ldtk models.\n",
    "- `'off'` : Will use the fixed value provided in the input file\n",
    "Default is `'independent'`\n",
    "#### max_batch_parameters : int, optional\n",
    "The maximum number of parameters to use in a single retrieval.\n",
    "Default is `25`.\n",
    "#### batch_overlap : int, optional\n",
    "The number of epochs to overlap in each batch. This will be adhered\n",
    "to where possible. Default is `2`.\n",
    "#### dlogz : float, optional\n",
    "Retrieval iteration will stop when the estimated contribution of\n",
    "the remaining prior volume to the total evidence falls below this\n",
    "threshold. Explicitly, the stopping criterion is\n",
    "```python\n",
    "ln(z + z_est) - ln(z) < dlogz,\n",
    "```\n",
    "where z is the current evidence\n",
    "from all saved samples and z_est is the estimated contribution from\n",
    "the remaining volume. The default is \n",
    "```python\n",
    "1e-3 * (nlive - 1) + 0.01.\n",
    "```\n",
    "#### maxiter : int or `None`, optional\n",
    "The maximum number of iterations to run. If `None`, will\n",
    "continue until stopping criterion is reached. Default is `None`.\n",
    "#### maxcall : int or `None`, optional\n",
    "The maximum number of likelihood calls in retrieval. If None, will\n",
    "continue until stopping criterion is reached. Default is `None`.\n",
    "#### dynesty_bounding : {`'none'`, `'single'`, `'multi'`, `'balls'`, `'cubes'`}, optional\n",
    "The decomposition to use in sampling. Default is `'multi'`.\n",
    "#### normalise : bool, optional\n",
    "If True, will assume that the light curves have not been normalised and\n",
    "will fit normalisation constants within the retrieval. The range to\n",
    "fit normalisation constants c_n are automatically detected using\n",
    "```python\n",
    "1/f_min <= c_n <= 1/f_max\n",
    "```\n",
    "as the default range, where f_min and f_max are the minimum and maximum\n",
    "flux values for a given light curve. Default is `True`.\n",
    "#### detrend : bool, optional\n",
    "If True, will initialise detrending fitting. Default is `True`.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "A whole lot of data to science!\n",
    "Zipped files are found in:\n",
    "```python\n",
    "firefly/WASP-43 b timestamp.gz.tar\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
